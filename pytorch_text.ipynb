{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_text.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMAb/LTb0mXLuWdP3hmN81J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alecbidaran/Pytorch_excersies/blob/main/pytorch_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c3xAiq6vRQU",
        "outputId": "cd5b5fe2-14b2-4e63-b87f-12a5eac9c1f4"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.manual_seed(123)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fce09fbac30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeK5MAXFvbxb"
      },
      "source": [
        "import random\n",
        "from torchtext.legacy import data, datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ytyy_va2rA4"
      },
      "source": [
        "TEXT_FIELD = data.Field(tokenize = data.get_tokenizer(\"basic_english\"), include_lengths = True)\n",
        "LABEL_FIELD = data.LabelField(dtype = torch.float)\n",
        "\n",
        "train_dataset, test_dataset = datasets.IMDB.splits(TEXT_FIELD, LABEL_FIELD)\n",
        "train_dataset, valid_dataset = train_dataset.split(random_state = random.seed(123))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQzbCx5U2uAY"
      },
      "source": [
        "MAX_VOCAULARY_SIZE=25000\n",
        "TEXT_FIELD.build_vocab(train_dataset,max_size=MAX_VOCAULARY_SIZE)\n",
        "LABEL_FIELD.build_vocab(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtBoAIaIHKZQ"
      },
      "source": [
        "batch_size=64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_data_iterator,valid_data_iterator,test_data_iterator=data.BucketIterator.splits((train_dataset,valid_dataset,test_dataset),\n",
        "                                                                                       batch_size=batch_size,\n",
        "                                                                                       sort_within_batch = True,\n",
        "                                                                                       device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OyBch6NJPV9"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, PackedSequence\n",
        "\n",
        "def cuda_pack_padded_sequence(input, lengths, batch_first=False, enforce_sorted=True):\n",
        "    lengths = torch.as_tensor(lengths, dtype=torch.int64)\n",
        "    lengths = lengths.cpu()\n",
        "    if enforce_sorted:\n",
        "      sorted_indices = None\n",
        "    else:\n",
        "      lengths, sorted_indices = torch.sort(lengths, descending=True)\n",
        "      sorted_indices = sorted_indices.to(input.device)\n",
        "      batch_dim = 0 if batch_first else 1\n",
        "      input = input.index_select(batch_dim, sorted_indices)\n",
        "\n",
        "    data, batch_sizes = \\\n",
        "    torch._C._VariableFunctions._pack_padded_sequence(input, lengths, batch_first)\n",
        "    return PackedSequence(data, batch_sizes, sorted_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smaGXfd1QtMe"
      },
      "source": [
        "from torch import nn "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMkJKDCVRYv1",
        "outputId": "fbf5e688-d4d9-4f7b-c81d-a8227e702236"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, vocabulary_size, embedding_dimension, hidden_dimension, output_dimension, dropout, pad_index):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.Embedding(vocabulary_size,embedding_dimension,pad_index)\n",
        "    self.lstm1=nn.LSTM(embedding_dimension,hidden_dimension,bidirectional=True,num_layers=1,\n",
        "                           dropout=dropout)\n",
        "    self.linear=nn.Linear(hidden_dimension*2,output_dimension)\n",
        "    self.dropout=nn.Dropout()\n",
        "  def forward(self, sequence, sequence_lengths=None):\n",
        "    if sequence_lengths is None:\n",
        "      sequence_lengths = torch.LongTensor([len(sequence)])\n",
        "    embedded_output=self.dropout(self.embedding(sequence))\n",
        "    if torch.cuda.is_available():\n",
        "      packed_embded=cuda_pack_padded_sequence(embedded_output,sequence_lengths)\n",
        "    else:\n",
        "      packed_embded=nn.utils.rnn.pack_padded_sequence(embedded_output,sequence_lengths)\n",
        "    packed_out,(hidden_state,cell_state)=self.lstm1(packed_embded)\n",
        "    op,op_lenght=nn.utils.rnn.pad_packed_sequence(packed_out)\n",
        "    hidden_output = torch.cat((hidden_state[-2,:,:], hidden_state[-1,:,:]), dim = 1) \n",
        "    return self.linear(hidden_output)\n",
        "INPUT_DIMENSION = len(TEXT_FIELD.vocab)\n",
        "EMBEDDING_DIMENSION = 100\n",
        "HIDDEN_DIMENSION = 32\n",
        "OUTPUT_DIMENSION = 1\n",
        "DROPOUT = 0.5\n",
        "PAD_INDEX = TEXT_FIELD.vocab.stoi[TEXT_FIELD.pad_token]\n",
        "\n",
        "lstm_model = LSTM(INPUT_DIMENSION, \n",
        "            EMBEDDING_DIMENSION, \n",
        "            HIDDEN_DIMENSION, \n",
        "            OUTPUT_DIMENSION, \n",
        "            DROPOUT, \n",
        "            PAD_INDEX)\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIYnU1QwT9rY"
      },
      "source": [
        "UNK_INDEX=TEXT_FIELD.vocab.stoi[TEXT_FIELD.unk_token]\n",
        "lstm_model.embedding.weight.data[UNK_INDEX] = torch.zeros(EMBEDDING_DIMENSION)\n",
        "lstm_model.embedding.weight.data[PAD_INDEX] = torch.zeros(EMBEDDING_DIMENSION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hwTd2kQUUsc"
      },
      "source": [
        "optim = torch.optim.Adam(lstm_model.parameters())\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "lstm_model = lstm_model.to(device)\n",
        "loss_func = loss_func.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_004e7IU4UJ"
      },
      "source": [
        "def accuracy_metric(predictions, ground_truth):\n",
        "    \"\"\"\n",
        "    Returns 0-1 accuracy for the given set of predictions and ground truth\n",
        "    \"\"\"\n",
        "    # round predictions to either 0 or 1\n",
        "    rounded_predictions = torch.round(torch.sigmoid(predictions))\n",
        "    success = (rounded_predictions == ground_truth).float() #convert into float for division \n",
        "    accuracy = success.sum() / len(success)\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bozL6k7IU-8Z"
      },
      "source": [
        "def train(model,data_iterator,optim,loss_func):\n",
        "  loss = 0\n",
        "  accuracy = 0\n",
        "  model.train()\n",
        "  optim.zero_grad()\n",
        "  for sequence_batch in data_iterator:\n",
        "    sequence,sequence_lenght=sequence_batch.text\n",
        "    preds=lstm_model(sequence,sequence_lenght).squeeze(1)\n",
        "    loss_c=loss_func(preds,sequence_batch.label)\n",
        "    acc_c=accuracy_metric(preds,sequence_batch.label)\n",
        "    loss_c.backward()\n",
        "    optim.step()\n",
        "    loss+=loss_c.item()\n",
        "    accuracy+=acc_c.item()\n",
        "  return loss/len(data_iterator), accuracy/len(data_iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJIy33M-WNVS"
      },
      "source": [
        "def validate(model, data_iterator, loss_func):\n",
        "    loss = 0\n",
        "    accuracy = 0\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for curr_batch in data_iterator:\n",
        "            sequence, sequence_lengths = curr_batch.text\n",
        "            preds = model(sequence, sequence_lengths).squeeze(1)\n",
        "            \n",
        "            loss_curr = loss_func(preds, curr_batch.label)\n",
        "            accuracy_curr = accuracy_metric(preds, curr_batch.label)\n",
        "\n",
        "            loss += loss_curr.item()\n",
        "            accuracy += accuracy_curr.item()\n",
        "        \n",
        "    return loss/len(data_iterator), accuracy/len(data_iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwS_YSgOWQjP",
        "outputId": "de7ada23-0bee-4946-f668-ac759bb64799"
      },
      "source": [
        "num_epochs = 10\n",
        "best_validation_loss = float('inf')\n",
        "\n",
        "for ep in range(num_epochs):\n",
        "\n",
        "    time_start = time.time()\n",
        "    \n",
        "    training_loss, train_accuracy = train(lstm_model, train_data_iterator, optim, loss_func)\n",
        "    validation_loss, validation_accuracy = validate(lstm_model, valid_data_iterator, loss_func)\n",
        "    \n",
        "    time_end = time.time()\n",
        "    time_delta = time_end - time_start \n",
        "    \n",
        "    if validation_loss < best_validation_loss:\n",
        "        best_validation_loss = validation_loss\n",
        "        torch.save(lstm_model.state_dict(), 'lstm_model.pt')\n",
        "    \n",
        "    print(f'epoch number: {ep+1} | time elapsed: {time_delta}s')\n",
        "    print(f'training loss: {training_loss:.3f} | training accuracy: {train_accuracy*100:.2f}%')\n",
        "    print(f'validation loss: {validation_loss:.3f} |  validation accuracy: {validation_accuracy*100:.2f}%')\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch number: 1 | time elapsed: 22.244837045669556s\n",
            "training loss: 0.666 | training accuracy: 58.77%\n",
            "validation loss: 0.628 |  validation accuracy: 65.58%\n",
            "\n",
            "epoch number: 2 | time elapsed: 19.85049057006836s\n",
            "training loss: 0.603 | training accuracy: 67.03%\n",
            "validation loss: 0.587 |  validation accuracy: 68.89%\n",
            "\n",
            "epoch number: 3 | time elapsed: 19.678786277770996s\n",
            "training loss: 0.506 | training accuracy: 75.60%\n",
            "validation loss: 0.708 |  validation accuracy: 69.80%\n",
            "\n",
            "epoch number: 4 | time elapsed: 19.827998876571655s\n",
            "training loss: 0.445 | training accuracy: 79.16%\n",
            "validation loss: 0.541 |  validation accuracy: 73.47%\n",
            "\n",
            "epoch number: 5 | time elapsed: 19.677167654037476s\n",
            "training loss: 0.399 | training accuracy: 82.22%\n",
            "validation loss: 0.553 |  validation accuracy: 77.97%\n",
            "\n",
            "epoch number: 6 | time elapsed: 19.56511950492859s\n",
            "training loss: 0.365 | training accuracy: 83.69%\n",
            "validation loss: 0.463 |  validation accuracy: 78.73%\n",
            "\n",
            "epoch number: 7 | time elapsed: 19.64629888534546s\n",
            "training loss: 0.326 | training accuracy: 86.31%\n",
            "validation loss: 0.497 |  validation accuracy: 79.38%\n",
            "\n",
            "epoch number: 8 | time elapsed: 19.698770999908447s\n",
            "training loss: 0.305 | training accuracy: 87.14%\n",
            "validation loss: 0.452 |  validation accuracy: 81.14%\n",
            "\n",
            "epoch number: 9 | time elapsed: 19.554710865020752s\n",
            "training loss: 0.282 | training accuracy: 88.30%\n",
            "validation loss: 0.495 |  validation accuracy: 81.59%\n",
            "\n",
            "epoch number: 10 | time elapsed: 19.691554307937622s\n",
            "training loss: 0.285 | training accuracy: 88.00%\n",
            "validation loss: 0.468 |  validation accuracy: 80.05%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6VVV6gNWTJM"
      },
      "source": [
        "def test(model,senteces):\n",
        "  tokenized=data.get_tokenizer(\"basic_english\")(senteces)\n",
        "  tokenized=[TEXT_FIELD.vocab.stoi[t] for t in tokenized]\n",
        "  model_input=torch.LongTensor(tokenized).to(device)\n",
        "  model_input=model_input.unsqueeze(1)\n",
        "  pred=torch.sigmoid(model(model_input))\n",
        "  return pred.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnK7B8oFZa9z",
        "outputId": "ee5dc4d5-614e-417b-875c-5d422f47d794"
      },
      "source": [
        "print(test(lstm_model, \"This film is horrible\"))\n",
        "print(test(lstm_model, \"This film will be houseful for weeks\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0017328496323898435\n",
            "0.9640718698501587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHupqWTFZemM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}